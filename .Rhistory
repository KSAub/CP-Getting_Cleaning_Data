library(XML)
fileURL <- https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <-xmlTreeParse(fileURL, useInternal=TRUE)
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <-xmlTreeParse(fileURL, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
library(XML)
fileURL <-  "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileURL <-  "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
names(rootNode[[1]])
names(rootNode[[1]][[1]])
zips <- xpathSApply(rootNode, "//zipcode", xmlValue ==21231 )
zips <- xpathSApply(rootNode, "//zipcode", xmlValue )
zips
zips <- xpathSApply(rootNode, "/row[zipcode=21231]", xmlValue )
zips
zips <- xpathSApply(doc, "/row[zipcode=21231]", xmlValue )
zips <- xpathSApply(doc, "//row[zipcode=21231]", xmlValue )
head(zips)
length(zips)
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile = "commIdaho.csv", method = "curl")
library(data.table)
?fread
DT <- fread("commIdaho.csv")
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
means <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time(means)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15) mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15), mean(DT[DT$SEX==2,]$pwgtp15))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1], rowMeans(DT)[DT$SEX==2])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
sapply(split(DT$pwgtp15,DT$SEX),mean)
?system.time
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
DT[,mean(pwgtp15),by=SEX]
mean(DT$pwgtp15,by=DT$SEX)
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
install.packages("xlsx")
library(xlsx)
library(xlsx)
library(swirl)
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydv)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package =="swirl")
filter(cran, r_version == "3.1.1", country == "US" )
?Comparison
filter(cran, r_version <= "3.1.1", country == "IN" )
filter(cran, r_version <= "3.0.2", country == "IN" )
filter(cran, country == "US" | country == "IN" )
filter(cran, size > 100500, r_os == "linux_gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
set.seed(13435)
X <- data.frame("var1"=sample(1:5), "var2"=sample(6:10), "var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2,"var2"]
X[(X$var1 <= 3 & X$var3 >11),]
load("plyr")
install.packages("plyr")
library(plyr)
arrange(X, var1)
arrange(X,desc)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X, rnorm(5))
Y
getwd()
if(!file.exists("./data")){dir.create("./data")}
fileURL <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile = "./data/restaurants.csv", method="curl")
restData <- read.csv("./data/restaurants.csv")
head(restData,ne=3)
head(restData,n=3)
tail(restData, n=3)
summarise(restData)
summary(restData)
str(restData)
restData[restData$zipCode %in% c("21212","21213")]
restData[restData$zipCode %in% c("21212","21213"),]
data("UCBAdmissions")
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~Gender + Admit, data=DF)
xt
data("warpbreaks")
warpbreaks$replicate <- rep(1:9, len = 54)
xt <- xtabs(breaks ~., data = warpbreaks)
xt
ftable(xt)
s1 <- seq(1,10,by=2); s1
s2 <- seq(1,10, length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
yesno <- sample (c("yes","no"), size=10, replace = TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
relevel(yesnofac, ref="yes")
as.numeric(yesnofac)
library(reshape2)
install.packages("reshape")
library(reshape)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id =c("carname", "gear","cyl"),measure.vars = c("mpg","hp"))
head(carMelt,n=3)
carMelt
cylData <- dcast
cylData <- dcast(carMelt, cyl ~ variable)
cylData
cylData <- dcast(carMelt, cyl ~ variable,mean())
cylData <- dcast(carMelt, cyl ~ variable,mean)
cylData
head(InsectSprays)
tapply(InsectSprays$count, InsectSprays$spray,sum)
spIns <- split(InsectSprays$count, InsectSprays$spray)
spIns
sprCount <- lapply
sprCount <- lapply(spIns,sum);sprCount
unlist(sprCount)
ddply(InsectSprays,.(spray),summarize, sum=sum(count))
library(dplyr)
chicago <- readRDS("chicago.rds")
if(!file.exists("./data")){dir.create("./data")}
fileURL1 = "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileURL2 = "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileURL1,destfile = "./data/reviews.csv", method = "curl")
download.file(fileURL2,destfile = "./data/solutions.csv", method = "curl")
reviews = read.csv("./data/reviews.csv"); solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
head(solutions,2)
names(reviews)
names(solutions)
mergedData = merge(reviews, solutions, by.x = "solution_id", by.y = "id", all = TRUE)
head(mergedData)
if(!file.exists("./data")){dir.create("./data")}
fileURL3 = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileURL3, destfile = "./data/UScommunities.csv", method = "curl")
uscomm <- read.csv("./data/UScommunities.csv")
colnames(uscomm)
names(uscomm)
head(uscomm[,"POWSP"])
View(uscomm)
head(uscomm[,"ACR"])
uscomm[,"ACR" == 3]
uscomm[,("ACR" == 3)]
uscomm[uscomm$ACR =3,]
uscomm[uscomm$ACR ==3,]
head(uscomm[uscomm$ACR ==3,])
agricultureLogical <- uscomm[(uscomm$ACR == 3 & uscomm$AGS ==6),]
head(agricultureLogical)
uscommACR <- uscomm[which(agricultureLogical)]
uscommACR <- uscomm[which(agricultureLogical == TRUE)]
uscommACR <- uscomm[which(agricultureLogical = TRUE)]
uscommACR <- uscomm[which(agricultureLogical),]
uscommACR <- uscomm[which(agricultureLogical==TRUE),]
head(uscommACR,3)
show <- uscommACR[10:13,1:5]
show
show <- uscommACR[1:5,10:13]
show
View(uscommACR)
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
crn
cran
?group_by()
?group_by
by_package <- group_by(cran, package)
by_package
?summarize
summarise(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
?filter
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
?arrange
top_counts_sorted <- arrange(top_counts, count, desc)
top_counts_sorted <- desc(arrange(top_counts, count))
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique()))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
?chain
??chain
submit()
View(result3)
submit
submit()
submit()
submit()
submit
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(sex_class, count, male_1, female_1, male_2, female_2, -grade)
res <- gather(key = sex_class, value =  count, male_1, female_1, male_2, female_2, -grade)
res <- gather(students2, key = sex_class, value =  count, male_1, female_1, male_2, female_2, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, into = c("sex", "class"))
submit()
students3
submit()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed <- mutate(passed, status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
packageVersion("dplyr")
bind_rows(passed, failed)
sat
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
month(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, now())
this_moment <- update(this_moment, hours = now(), minutes = now())
this_moment
nyc <- now
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval
how_long <- interval(last_time, arrive)
as.period
as.period(how_long)
stopwatch()
getwd()
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile = "./data/cameras.csv",method ="curl")
cameraData <- read.csv("./data/cameras.csv")
names(cameraData)
tolower(names(cameraData))
splitNames <- strsplit(names(cameraData),"\\.")
splitNames[[5]]
splitNames[[6]]
mylist <- list(letters = c("A", "b","c"), numbers = 1:3, matrix(1:25, ncol = 5))
head(mylist)
mylist[1]
splitNames[[6]][1]
firstElement <- function(x){x[1]}
sapply(splitNames, firstElement)
reviews <- read.csv("./data/reviews.csv"); solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
head(solutions,2)
sub("_","",names(reviews),)
testName <- "this_is_a_test"
gsub("_","",testName)
grep("Alameda",cameraData$intersection)
table(grepl("Alameda", cameraData$intersection))
cameraData2 <- cameraData[!grepl"Alameda", cameraData$intersection]
cameraData2 <- cameraData[!grepl("Alameda", cameraData$intersection),]
cameraData2
head(cameraData2,2)
grep("Alameda", cameraData$intersection, value=TRUE)
?grep
library(stringr)
packageVersion("stringr")
nchar("Jeffrey Leek")
substr("Jeffrey Leek",1,7)
paste("Jeffrey", "Leek")
paste0("Kirsten","Scherer")
str_trim
str_trim("Kscherer    ")
d1 = date()
d2 <- Sys.Date()
d2
d1 <- date()
d1 <- date(x)
class(d2)
format(d2, "%a %b %d")
format(d2, "%A %m %d %Y")
format(d2, "%A %B %d %Y")
x = c("1jan1960", "2jan1960", "31mar1960", "30jul1960"); z = as.Date(x, "%d%b%Y")
z
z[1] - z[2]
fileUrl = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
getwd()
download.file(url, destfile = "UScommunities.csv", method = "curl")
download.file(filUrl, destfile = "UScommunities.csv", method = "curl")
download.file(fileUrl, destfile = "UScommunities.csv", method = "curl")
commDF <- read.csv("UScommunities.csv")
View(commDF)
names(commDF)
strsplit(names(commDF),"wgtp")
splitNames <- strsplit(names(commDF),"wgtp")
splitNames[123]
fileUrl1 = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "GDP.csv")
gdpfile <- read.csv("gdp.csv")
View(gdpfile)
download.file(fileUrl1, destfile = "GDP.csv")
gdpfile <- read.csv("gdp.csv")
View(gdpfile)
gdpfile <- read.csv("gdp.csv", skip = 4)
gdpread <- gdpfile[1:190,]
View(gdpread)
gdpread <- gdpfile[1:190,c(1,2,4,5)]
gdpread <- sub(",","",gdpread$X.4)
gdpread <- gdpfile[1:190,c(1,2,4,5)]
View(gdpfile)
View(gdpread)
gsub
gsub(",","",gdpread$X.4)
?mutate
library(dplyr)
?mutate
mutate(gdpread,X.4 = gsub(",","",gdpread$X.4))
mean(gdpread$X.4)
View(gdpread)
gdpreadm <- mutate(gdpread,X.4 = gsub(",","",gdpread$X.4))
View(gdpreadm)
dim(gdpreadm)
typeof(gdpreadm$X.4)
gdpreadm$X.4 <- as.numeric(gdpreadm$X.4)
typeof(gdpreadm$X.4)
mean(gdpread$X.4)
gdpreadm <- mutate(gdpread,X.4 = as.numeric(gsub(",","",gdpread$X.4)))
View(gdpreadm)
mean(gdpread$X.4)
typeof(gdpreadm$X.4)
gdpreadm <- mutate(gdpread,X.4 = as.integer(gsub(",","",gdpread$X.4)))
typeof(gdpreadm$X.4)
mean(gdpread$X.4)
mean(gdpreadm$X.4)
View(gdpfile)
grep("^United", gdpfile$X.3)
grep("^United$", gdpfile$X.3)
grep("United$", gdpfile$X.3)
grep("*United", gdpfile$X.3)
grep("^United$", gdpfile$X.3)
fileUrl2 = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl2, destfile = "edustats.csv")
edustats <- read.csv("edustats.csv")
View(edustats)
View(gdpfile)
View(gdpread)
gdpread <- gdpfile[c(1:190,192:215,217,219:231),c(1,2,4,5)]
View(gdpread)
names(gdpread)
named_commas(edustats)
names(edustats)
names(gdpread)
edustatRead <- edustats[,c(1,10)]
View(edustatRead)
mergedData <- merge(edustatRead,gdpread, by.x = "CountryCode", by.y = "X")
head(mergedData)
View(mergedData)
grep("[Jj]une",mergedData$Special.Notes)
length(grep("[Jj]une",mergedData$Special.Notes))
install.packages("quantmod")
library(quantmod)
library(quantmod)amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
View(amzn)
grep("^2012.",sampleTimes)
2012ST <- grep("^2012.",sampleTimes)
sampleT2012 <- grep("^2012.",sampleTimes)
head(sampleT2012)
sampleTimes <- grep("^2012.",sampleTimes)
sampleTimes = index(amzn)
wd <- weekdays(as.Date(sampleTimes))
head(wd)
sampleWD <- mutate(sampleTimes, weekday = weekdays(as.Date(sampleTimes)))
DF <- as.data.frame(sampleTimes)
head(DF)
sampleWD <- mutate(DF, weekday = weekdays(as.Date(sampleTimes)))
head(sampleWD)
grep("^2012.",sampleWD)
grep("^2012.",sampleWD$sampleTimes)
table(grepl("^2012.",sampleWD$sampleTimes))
dates2012 <- sampleWD[!grepl("^2012.",sampleWD$sampleTimes),]
head(dates2012)
dates2012 <- sampleWD[grep("^2012.",sampleWD$sampleTimes,value = TRUE),]
head(dates2012)
View(dates2012)
View(sampleWD)
dates2012 <- sampleWD[grep("^2012.",sampleWD$sampleTimes),]
View(dates2012)
table(grepl("Montag",dates2012$weekday))
View(mergedData)
length(grep("June",mergedData$Special.Notes))
length(grep("+June",mergedData$Special.Notes))
length(grep("*: June",mergedData$Special.Notes))
getwd()
setwd("~/Desktop/Coursera/DS/Getting_Cleaning_Data/course_project/CP-Getting_Cleaning_Data")
?md
